{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "**Q:** Neptune AI lưu dữ liệu ở đâu\n",
    "\n",
    "**A:** Free Neptune cho phép lưu dữ liệu trên cloud, Storage max 200GB, được 1 active project và max 5 customers view.\n",
    "Source : https://neptune.ai/pricing\n",
    "\n",
    "---\n",
    "\n",
    "## Question 2\n",
    "**Q:** Vấn đề về Hyperparameters trong hyperparameter tunning method\n",
    "\n",
    "**A:**  \n",
    "\n",
    "- Thường thì sẽ là 1 giá trị/ khoảng giá trị mà người viết ra algorythm sẽ định nghĩa, và sẽ hoạt động trên phần lớn các trường hợp.\n",
    "- Việc tunning các hyperparameters này có ảnh hưởng rất nhỏ tới kết quả.\n",
    "- Với các trường hợp extreme thì có thể hyperparameter tuning với hyperparameter này  \n",
    "- Ví dụ với TPE có 1 hyperparameter là gamma\n",
    "- Gamma có thể được access gọi TPE sampler (gammma = function default_gamma)\n",
    "\n",
    "```python\n",
    "def default_gamma(x: int) -> int:\n",
    "    return min(int(np.ceil(0.1 * x)), 25)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Vẽ thêm validation loss cho từng fold như training loss\n",
    "gộp validation loss curve trên cùng 1 graph\n",
    "\n",
    "normalize dataset \n",
    "\n",
    "Continuous learning, lifelong learning (literature review), xem các phương pháp giải quyết forgetful learning. \n",
    "literature review: giải quyết vấn đề forgeting. (thực tế trên vd nào, test trên tập dữ liệu nào, vd thực tế, tại sao cần giải quyết, evaluate như thế nào.)\n",
    "làm powerpoint()\n",
    "tìm hiểu bao quát trước -> sâu ()\n",
    "\n",
    "\n",
    "\n",
    "tìm báo theo hướng robotic, công nghiệp, anomaly detection.\n",
    "implement cho toy example\n",
    "ứng dụng cho Mnist, Cifar\n",
    "ssh\n",
    "slurm"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

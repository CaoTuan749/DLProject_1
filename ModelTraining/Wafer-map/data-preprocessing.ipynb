{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from PIL import Image\n",
    "\n",
    "class WaferMapDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 file_path,\n",
    "                 split='train',       # 'train' or 'test'\n",
    "                 oversample=False,\n",
    "                 target_dim=(224, 224),\n",
    "                 task_classes=None\n",
    "                ):\n",
    "        self.file_path = file_path\n",
    "        self.split = split.lower()\n",
    "        self.oversample = oversample\n",
    "        self.target_dim = target_dim\n",
    "        self.task_classes = task_classes\n",
    "\n",
    "        # 1) Load DataFrame\n",
    "        df = pd.read_pickle(self.file_path)\n",
    "\n",
    "        # 2) Replace [0,0] with 'Unknown'\n",
    "        def replace_zero_zero(x):\n",
    "            if isinstance(x, (list, np.ndarray)) and np.array_equal(x, [0, 0]):\n",
    "                return 'Unknown'\n",
    "            return x\n",
    "        if 'failureType' not in df.columns:\n",
    "            raise KeyError(\"Missing 'failureType' column.\")\n",
    "        df['failureType'] = df['failureType'].apply(replace_zero_zero)\n",
    "        if 'trainTestLabel' not in df.columns:\n",
    "            raise KeyError(\"Missing 'trainTestLabel' column.\")\n",
    "        df['trainTestLabel'] = df['trainTestLabel'].apply(replace_zero_zero)\n",
    "\n",
    "        # 3) Filter out 'none' or 'Unknown'\n",
    "        valid_mask = ~df['failureType'].isin(['none', 'Unknown'])\n",
    "        df = df[valid_mask].reset_index(drop=True)\n",
    "\n",
    "        # 4) Resize wafer maps\n",
    "        def resize_wafer_map(wmap):\n",
    "            img = Image.fromarray(wmap.astype('uint8'))\n",
    "            img_resized = img.resize(self.target_dim, Image.Resampling.LANCZOS)\n",
    "            return np.array(img_resized)\n",
    "        df['waferMap_resized'] = df['waferMap'].apply(resize_wafer_map)\n",
    "\n",
    "        # 5) Flatten wafer maps from the resized images.\n",
    "        df['waferMap_flat'] = df['waferMap_resized'].apply(lambda x: x.flatten())\n",
    "\n",
    "        # 6) Separate train & test\n",
    "        df_train = df[df['trainTestLabel'] == 'Training'].reset_index(drop=True)\n",
    "        df_test  = df[df['trainTestLabel'] == 'Test'].reset_index(drop=True)\n",
    "        if len(df_train) == 0:\n",
    "            raise ValueError(\"No training samples with 'trainTestLabel' == 'Training'!\")\n",
    "\n",
    "        # 7) Fit LabelEncoder on the training set\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(df_train['failureType'].values)\n",
    "        self.encoder = encoder\n",
    "\n",
    "        # 8) If task_classes is provided, filter both training and test sets.\n",
    "        if self.task_classes is not None:\n",
    "            df_train['encoded'] = encoder.transform(df_train['failureType'].values)\n",
    "            df_test['encoded'] = encoder.transform(df_test['failureType'].values)\n",
    "            df_train = df_train[df_train['encoded'].isin(self.task_classes)].reset_index(drop=True)\n",
    "            df_test = df_test[df_test['encoded'].isin(self.task_classes)].reset_index(drop=True)\n",
    "            # Recalculate waferMap_flat after filtering.\n",
    "            df_train['waferMap_flat'] = df_train['waferMap_resized'].apply(lambda x: x.flatten())\n",
    "            df_test['waferMap_flat'] = df_test['waferMap_resized'].apply(lambda x: x.flatten())\n",
    "            new_encoder = LabelEncoder()\n",
    "            new_encoder.fit(df_train['failureType'].values)\n",
    "            self.encoder = new_encoder\n",
    "\n",
    "        # 9) Oversample if in training split and oversample is True.\n",
    "        if self.oversample and self.split == 'train':\n",
    "            X_train = np.stack(df_train['waferMap_flat'].values).astype('float32')\n",
    "            y_train = df_train['failureType'].values\n",
    "            ros = RandomOverSampler(random_state=42)\n",
    "            X_res, y_res = ros.fit_resample(X_train, y_train)\n",
    "            df_train = pd.DataFrame({\n",
    "                'waferMap_flat': list(X_res),\n",
    "                'failureType': y_res\n",
    "            }).reset_index(drop=True)\n",
    "\n",
    "        # 10) Choose the final split.\n",
    "        df_split = df_train if self.split == 'train' else df_test\n",
    "\n",
    "        # 11) Encode labels.\n",
    "        X_data = np.stack(df_split['waferMap_flat'].values).astype('float32')\n",
    "        y_data = df_split['failureType'].values\n",
    "        y_enc  = self.encoder.transform(y_data)\n",
    "\n",
    "        self.X = X_data\n",
    "        self.y = y_enc\n",
    "        self.num_samples = len(self.X)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        wafer_map_flat = self.X[idx]\n",
    "        expected = self.target_dim[0] * self.target_dim[1]\n",
    "        if wafer_map_flat.size == expected:\n",
    "            wafer_map_tensor = torch.from_numpy(wafer_map_flat).float()\n",
    "            wafer_map_tensor = wafer_map_tensor.view(1, self.target_dim[0], self.target_dim[1]).repeat(3, 1, 1)\n",
    "        else:\n",
    "            raise ValueError(f\"Sample {idx} has size {wafer_map_flat.size}, expected {expected}. Check your data!\")\n",
    "        label_tensor = torch.tensor(self.y[idx], dtype=torch.long)\n",
    "        return wafer_map_tensor, label_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Number of samples: 10971\n",
      "Sample 0: shape = torch.Size([3, 224, 224]), label = 0\n",
      "Sample 1: shape = torch.Size([3, 224, 224]), label = 0\n",
      "Sample 2: shape = torch.Size([3, 224, 224]), label = 0\n",
      "Sample 3: shape = torch.Size([3, 224, 224]), label = 0\n",
      "Sample 4: shape = torch.Size([3, 224, 224]), label = 0\n",
      "\n",
      "Batch data shape: torch.Size([4, 3, 224, 224])\n",
      "Batch target shape: torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "# Testing the WaferMapDataset and DataLoader functionality\n",
    "\n",
    "from Wafer_data_dataset_resize import WaferMapDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Set up the dataset for a specific task (e.g., task_classes [0, 1])\n",
    "# Adjust task_classes if needed.\n",
    "task_classes = [2, 3]\n",
    "try:\n",
    "    dataset = WaferMapDataset(\n",
    "        file_path=\"D:/Waffer Data/WM811K.pkl\",\n",
    "        split='train',\n",
    "        oversample=False,\n",
    "        target_dim=(224, 224),\n",
    "        task_classes=task_classes\n",
    "    )\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "    print(\"Number of samples:\", len(dataset))\n",
    "\n",
    "    # Check a few individual samples\n",
    "    for i in range(min(5, len(dataset))):\n",
    "        sample, label = dataset[i]\n",
    "        print(f\"Sample {i}: shape = {sample.shape}, label = {label}\")\n",
    "\n",
    "    # Create a DataLoader and inspect a batch\n",
    "    dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "    batch = next(iter(dataloader))\n",
    "    data, target = batch\n",
    "    print(f\"\\nBatch data shape: {data.shape}\")   # Expecting (batch_size, 3, 224, 224)\n",
    "    print(f\"Batch target shape: {target.shape}\")   # Expecting (batch_size,)\n",
    "except Exception as e:\n",
    "    print(\"Error while testing dataset:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set label distribution:\n",
      "Label 0: 2417 samples\n",
      "Label 1: 8554 samples\n",
      "\n",
      "Test set label distribution:\n",
      "Label 0: 2772 samples\n",
      "Label 1: 1126 samples\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from Wafer_data_dataset_resize import WaferMapDataset\n",
    "\n",
    "task_classes = [2, 3]\n",
    "\n",
    "# Load the full training dataset (using all classes)\n",
    "train_dataset = WaferMapDataset(\n",
    "    file_path=\"D:/Waffer Data/WM811K.pkl\",\n",
    "    split=\"train\",\n",
    "    oversample=False,\n",
    "    target_dim=(224, 224),\n",
    "    task_classes=task_classes  # Using None loads all classes\n",
    ")\n",
    "train_labels = train_dataset.y\n",
    "train_counts = Counter(train_labels)\n",
    "print(\"Training set label distribution:\")\n",
    "for label, count in train_counts.items():\n",
    "    print(f\"Label {label}: {count} samples\")\n",
    "\n",
    "# Load the full test dataset (using all classes)\n",
    "test_dataset = WaferMapDataset(\n",
    "    file_path=\"D:/Waffer Data/WM811K.pkl\",\n",
    "    split=\"test\",\n",
    "    oversample=False,\n",
    "    target_dim=(224, 224),\n",
    "    task_classes=task_classes  # Using None loads all classes\n",
    ")\n",
    "test_labels = test_dataset.y\n",
    "test_counts = Counter(test_labels)\n",
    "print(\"\\nTest set label distribution:\")\n",
    "for label, count in test_counts.items():\n",
    "    print(f\"Label {label}: {count} samples\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
